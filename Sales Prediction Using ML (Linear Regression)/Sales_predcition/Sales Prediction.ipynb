{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OG0LBz-irMVh"
   },
   "source": [
    "Train Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 847,
     "status": "ok",
     "timestamp": 1731241630032,
     "user": {
      "displayName": "Ned Palom",
      "userId": "06455553497609884633"
     },
     "user_tz": -600
    },
    "id": "_kvQu8prrQFG",
    "outputId": "7b332145-d9a1-4beb-c5a5-50fca1a78eb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in each column:\n",
      "Item_Identifier                 0\n",
      "Item_Weight                  1463\n",
      "Item_Fat_Content                0\n",
      "Item_Visibility                 0\n",
      "Item_Type                       0\n",
      "Item_MRP                        0\n",
      "Outlet_Identifier               0\n",
      "Outlet_Establishment_Year       0\n",
      "Outlet_Size                  2410\n",
      "Outlet_Location_Type            0\n",
      "Outlet_Type                     0\n",
      "Item_Outlet_Sales               0\n",
      "dtype: int64\n",
      "Data after dropping rows with missing values:\n",
      "     Item_Identifier  Item_Weight Item_Fat_Content  Item_Visibility  \\\n",
      "0              FDA15        9.300          Low Fat         0.016047   \n",
      "1              DRC01        5.920          Regular         0.019278   \n",
      "2              FDN15       17.500          Low Fat         0.016760   \n",
      "4              NCD19        8.930          Low Fat         0.000000   \n",
      "5              FDP36       10.395          Regular         0.000000   \n",
      "...              ...          ...              ...              ...   \n",
      "8517           FDF53       20.750              reg         0.083607   \n",
      "8518           FDF22        6.865          Low Fat         0.056783   \n",
      "8520           NCJ29       10.600          Low Fat         0.035186   \n",
      "8521           FDN46        7.210          Regular         0.145221   \n",
      "8522           DRG01       14.800          Low Fat         0.044878   \n",
      "\n",
      "               Item_Type  Item_MRP Outlet_Identifier  \\\n",
      "0                  Dairy  249.8092            OUT049   \n",
      "1            Soft Drinks   48.2692            OUT018   \n",
      "2                   Meat  141.6180            OUT049   \n",
      "4              Household   53.8614            OUT013   \n",
      "5           Baking Goods   51.4008            OUT018   \n",
      "...                  ...       ...               ...   \n",
      "8517        Frozen Foods  178.8318            OUT046   \n",
      "8518         Snack Foods  214.5218            OUT013   \n",
      "8520  Health and Hygiene   85.1224            OUT035   \n",
      "8521         Snack Foods  103.1332            OUT018   \n",
      "8522         Soft Drinks   75.4670            OUT046   \n",
      "\n",
      "      Outlet_Establishment_Year Outlet_Size Outlet_Location_Type  \\\n",
      "0                          1999      Medium               Tier 1   \n",
      "1                          2009      Medium               Tier 3   \n",
      "2                          1999      Medium               Tier 1   \n",
      "4                          1987        High               Tier 3   \n",
      "5                          2009      Medium               Tier 3   \n",
      "...                         ...         ...                  ...   \n",
      "8517                       1997       Small               Tier 1   \n",
      "8518                       1987        High               Tier 3   \n",
      "8520                       2004       Small               Tier 2   \n",
      "8521                       2009      Medium               Tier 3   \n",
      "8522                       1997       Small               Tier 1   \n",
      "\n",
      "            Outlet_Type  Item_Outlet_Sales  \n",
      "0     Supermarket Type1          3735.1380  \n",
      "1     Supermarket Type2           443.4228  \n",
      "2     Supermarket Type1          2097.2700  \n",
      "4     Supermarket Type1           994.7052  \n",
      "5     Supermarket Type2           556.6088  \n",
      "...                 ...                ...  \n",
      "8517  Supermarket Type1          3608.6360  \n",
      "8518  Supermarket Type1          2778.3834  \n",
      "8520  Supermarket Type1          1193.1136  \n",
      "8521  Supermarket Type2          1845.5976  \n",
      "8522  Supermarket Type1           765.6700  \n",
      "\n",
      "[4650 rows x 12 columns]\n",
      "Data after dropping columns with missing values:\n",
      "  Item_Identifier  Item_Weight Item_Fat_Content  Item_Visibility  \\\n",
      "0           FDA15        9.300          Low Fat         0.016047   \n",
      "1           DRC01        5.920          Regular         0.019278   \n",
      "2           FDN15       17.500          Low Fat         0.016760   \n",
      "4           NCD19        8.930          Low Fat         0.000000   \n",
      "5           FDP36       10.395          Regular         0.000000   \n",
      "\n",
      "      Item_Type  Item_MRP Outlet_Identifier  Outlet_Establishment_Year  \\\n",
      "0         Dairy  249.8092            OUT049                       1999   \n",
      "1   Soft Drinks   48.2692            OUT018                       2009   \n",
      "2          Meat  141.6180            OUT049                       1999   \n",
      "4     Household   53.8614            OUT013                       1987   \n",
      "5  Baking Goods   51.4008            OUT018                       2009   \n",
      "\n",
      "  Outlet_Size Outlet_Location_Type        Outlet_Type  Item_Outlet_Sales  \n",
      "0      Medium               Tier 1  Supermarket Type1          3735.1380  \n",
      "1      Medium               Tier 3  Supermarket Type2           443.4228  \n",
      "2      Medium               Tier 1  Supermarket Type1          2097.2700  \n",
      "4        High               Tier 3  Supermarket Type1           994.7052  \n",
      "5      Medium               Tier 3  Supermarket Type2           556.6088  \n",
      "Number of duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"train.csv\")\n",
    "#identify missing values in the columns\n",
    "missing_values = df.isnull().sum()\n",
    "print(\"Missing values in each column:\")\n",
    "print(missing_values)\n",
    "\n",
    "#remove rows with missing values\n",
    "\n",
    "df = df.dropna()\n",
    "print(\"Data after dropping rows with missing values:\")\n",
    "print(df)\n",
    "#data after dropping rows with missing values\n",
    "df = df.dropna()\n",
    "print(\"Data after dropping columns with missing values:\")\n",
    "print(df.head())\n",
    "\n",
    "#print the number of duplicate values\n",
    "duplicates = df.duplicated()\n",
    "print(\"Number of duplicate rows:\", duplicates.sum())\n",
    "\n",
    "#save the cleaned file\n",
    "df.to_csv(\"cleaned_dataset.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Jn3Cs-SrfEf"
   },
   "source": [
    "Encode Cleaned Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "executionInfo": {
     "elapsed": 787,
     "status": "ok",
     "timestamp": 1731242253692,
     "user": {
      "displayName": "Ned Palom",
      "userId": "06455553497609884633"
     },
     "user_tz": -600
    },
    "id": "hJGwDPn9rk44"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_encode = pd.read_csv('cleaned_dataset.csv')\n",
    "train_encode = pd.DataFrame(train_encode)\n",
    "\n",
    "# Separate features and target\n",
    "X = train_encode[['Item_Fat_Content', 'Item_Type', 'Outlet_Size', 'Outlet_Type']]\n",
    "y = train_encode['Item_Outlet_Sales']\n",
    "\n",
    "# Initialize the OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse_output=False, drop='first')  # `drop='first'` removes the first category to avoid multicollinearity\n",
    "\n",
    "# Fit and transform the features\n",
    "X_encoded = encoder.fit_transform(X)\n",
    "\n",
    "# Convert to DataFrame and add column names\n",
    "encoded_df = pd.DataFrame(X_encoded, columns=encoder.get_feature_names_out(X.columns))\n",
    "\n",
    "# Concatenate encoded features with target variable\n",
    "df_encoded = pd.concat([encoded_df, y], axis=1)\n",
    "\n",
    "#print(df_encoded)\n",
    "\n",
    "# Save the encoded dataframe to a CSV file\n",
    "df_encoded.to_csv(\"encoded_train_data.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e33D2Izrsds_"
   },
   "source": [
    "Model Training (Linear Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 825,
     "status": "ok",
     "timestamp": 1731242260412,
     "user": {
      "displayName": "Ned Palom",
      "userId": "06455553497609884633"
     },
     "user_tz": -600
    },
    "id": "DHYuJ92Nsh_G",
    "outputId": "3280dde3-e838-449a-b708-ea61633a4c13"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score  # Import necessary metrics\n",
    "import joblib\n",
    "\n",
    "# Load and prepare data\n",
    "data = pd.read_csv('encoded_train_data.csv')\n",
    "\n",
    "# Specify the name of the target column\n",
    "target_column = 'Item_Outlet_Sales' # Replace with your actual target column name\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop(columns=[target_column])  # Features (independent variables)\n",
    "y = data[target_column]  # Target (dependent variable)\n",
    "\n",
    "# Initialize the Linear Regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Fit the model with the entire dataset\n",
    "model.fit(X, y)\n",
    "\n",
    "# Make predictions on the same data (since we're not splitting)\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "# Evaluate the model using regression metrics\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y, y_pred)\n",
    "# Calculate R-squared (R2)\n",
    "r2 = r2_score(y, y_pred)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"R-squared (R2): {r2}\")\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(model, 'model_1')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_G4ARqngvYmM"
   },
   "source": [
    "Clean and Encode Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "executionInfo": {
     "elapsed": 603,
     "status": "ok",
     "timestamp": 1731242360552,
     "user": {
      "displayName": "Ned Palom",
      "userId": "06455553497609884633"
     },
     "user_tz": -600
    },
    "id": "FuKMOOVevbqk"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "#Load the train dataset\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "#Identify missing values in the columns\n",
    "\n",
    "missing_values = test.isnull().sum()\n",
    "\n",
    "#remove rows with missing values\n",
    "test = test.dropna()\n",
    "\n",
    "\n",
    "# Separate features and target\n",
    "X = test_encode[['Item_Fat_Content', 'Item_Type', 'Outlet_Size', 'Outlet_Type']]\n",
    "y = test_encode[['Item_Identifier','Outlet_Identifier']]\n",
    "\n",
    "# Initialize the OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse_output=False, drop='first')  # `drop='first'` removes the first category to avoid multicollinearity\n",
    "\n",
    "# Fit and transform the features\n",
    "X_encoded = encoder.fit_transform(X)\n",
    "\n",
    "# Convert to DataFrame and add column names\n",
    "encoded_df = pd.DataFrame(X_encoded, columns=encoder.get_feature_names_out(X.columns))\n",
    "\n",
    "# Concatenate encoded features with target variable\n",
    "df_encoded = pd.concat([encoded_df, y], axis=1)\n",
    "\n",
    "#print(df_encoded)\n",
    "\n",
    "# Save the encoded dataframe to a CSV file\n",
    "df_encoded.to_csv(\"encoded_test_data.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e1i8nSrctVvn"
   },
   "source": [
    "Merge Train and Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NUdgXf2Ctdug"
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "\n",
    "# Merge datasets on 'PassengerId' to add the 'Survived' column to the test dataset\n",
    "merged_data = test_data.merge(train_data[['Item_Identifier', 'Item_Outlet_Sales']], on='Item_Identifier', how='left')\n",
    "\n",
    "# Save the updated test dataset with the 'Survived' column\n",
    "merged_data.to_csv('train_test_merge.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lLdfUKD0widv"
   },
   "source": [
    "Encode Merge Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZtAFp5Xuwl-Q"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv(\"train_test_merge.csv\")\n",
    "\n",
    "df = pd.DataFrame(df)\n",
    "\n",
    "# Separate features and target\n",
    "X = train_encode[['Item_Fat_Content', 'Item_Type', 'Outlet_Type', 'Outlet_Size']]\n",
    "y = train_encode[['Item_Identifier',  'Outlet_Identifier', 'Item_Outlet_Sales']] # change to list of columns\n",
    "\n",
    "# Initialize the OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse_output=False, drop='first')  # `drop='first'` removes the first category to avoid multicollinearity\n",
    "\n",
    "# Fit and transform the features\n",
    "X_encoded = encoder.fit_transform(X)\n",
    "\n",
    "# Convert to DataFrame and add column names\n",
    "encoded_df = pd.DataFrame(X_encoded, columns=encoder.get_feature_names_out(X.columns))\n",
    "\n",
    "# Concatenate encoded features with target variable\n",
    "df_encoded = pd.concat([encoded_df, y], axis=1)\n",
    "\n",
    "#print(df_encoded)\n",
    "\n",
    "# Save the encoded dataframe to a CSV file\n",
    "df_encoded.to_csv(\"encode_merge_dataset.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VWexhkenw3oy"
   },
   "source": [
    "Predict the new Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 619,
     "status": "ok",
     "timestamp": 1731242419006,
     "user": {
      "displayName": "Ned Palom",
      "userId": "06455553497609884633"
     },
     "user_tz": -600
    },
    "id": "eJCzoUiCw6Jk",
    "outputId": "a8884a76-3332-48d3-f0e9-1c196a9eb5ab"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "# Load the model\n",
    "model = joblib.load('model_1')\n",
    "\n",
    "# Load the training data to get the original feature names\n",
    "training_data = pd.read_csv('encoded_train_data.csv')  # Replace with the path to your encoded training data\n",
    "training_features = training_data.drop(columns=['Item_Outlet_Sales']).columns  # Get the feature names from the training data\n",
    "\n",
    "# Load the test data\n",
    "test_data = pd.read_csv('encoded_test_data.csv')\n",
    "\n",
    "# Specify the name of the target column (if it exists in test data, remove it)\n",
    "target_column = 'Item_Outlet_Sales'  # Update to the actual target column\n",
    "\n",
    "# **Store 'Item_Identifier' and 'Outlet_Identifier' before dropping**\n",
    "index_ids = test_data['Item_Identifier'].tolist()\n",
    "index_ids2 = test_data['Outlet_Identifier'].tolist()\n",
    "\n",
    "# Drop the target column if it exists in test data\n",
    "if target_column in test_data.columns:\n",
    "    test_data = test_data.drop(columns=[target_column])\n",
    "\n",
    "# *** Drop 'Item_Identifier' and 'Outlet_Identifier' as they are not part of the model's features ***\n",
    "test_data = test_data.drop(columns=['Item_Identifier', 'Outlet_Identifier'])\n",
    "\n",
    "# Align the test data columns with the training data\n",
    "# Use 'training_features' as the reference for column order\n",
    "# and fill missing columns with 0\n",
    "test_data = test_data.reindex(columns=training_features, fill_value=0)\n",
    "\n",
    "\n",
    "# Make predictions for each row in the test data\n",
    "predictions = model.predict(test_data)  # Use the preprocessed test data\n",
    "\n",
    "# Create a DataFrame with Item_Identifier, Outlet_Identifier, and Item_Outlet_Sales columns\n",
    "results = pd.DataFrame({\n",
    "    'Item_Identifier': index_ids,\n",
    "    'Outlet_Identifier': index_ids2,\n",
    "    'Item_Outlet_Sales': predictions\n",
    "})\n",
    "\n",
    "# Display the results\n",
    "print(results)\n",
    "\n",
    "# Optionally, save the results to a CSV file\n",
    "results.to_csv('predictions.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 755
    },
    "executionInfo": {
     "elapsed": 3535,
     "status": "error",
     "timestamp": 1731238728428,
     "user": {
      "displayName": "Ned Palom",
      "userId": "06455553497609884633"
     },
     "user_tz": -600
    },
    "id": "KyqljCASxWsY",
    "outputId": "a031d3f2-e505-4129-b68a-a58251b5f551"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "# Load the model\n",
    "model = joblib.load('model_1')\n",
    "\n",
    "# Load the training data to get the original feature names\n",
    "training_data = pd.read_csv('encoded_train_data.csv')  # Replace with the path to your encoded training data\n",
    "training_features = training_data.drop(columns=['Item_Outlet_Sales']).columns  # Get the feature names from the training data\n",
    "\n",
    "# Load the test data\n",
    "test_data = pd.read_csv('encoded_test_data.csv')\n",
    "\n",
    "# Specify the name of the target column (if it exists in test data, remove it)\n",
    "target_column = 'Item_Identifier', 'Outlet_Type'  # Replace with your actual target column name, if needed\n",
    "\n",
    "# **Store 'Item_Identifier' before reindexing**\n",
    "index_ids = test_data['Item_Identifier'].tolist()\n",
    "\n",
    "# **Check if 'Outlet_Type' exists in test_data before accessing it**\n",
    "if 'Outlet_Type' in test_data.columns:\n",
    "    index_ids2 = test_data['Outlet_Type'].tolist()\n",
    "else:\n",
    "    # Handle the case where 'Outlet_Type' is missing\n",
    "    # You might want to:\n",
    "    # 1. Load the original test data to get 'Outlet_Type'\n",
    "    # 2. Create a placeholder list for index_ids2\n",
    "    # 3. Raise an error indicating the missing column\n",
    "    original_test_data = pd.read_csv('test.csv')  # Assuming your original test data is in 'test.csv'\n",
    "    index_ids2 = original_test_data['Outlet_Type'].tolist()\n",
    "    # Or create a placeholder:\n",
    "    # index_ids2 = ['Unknown'] * len(test_data)\n",
    "    # Or raise an error:\n",
    "    # raise KeyError(\"Column 'Outlet_Type' not found in test data.\")\n",
    "\n",
    "\n",
    "# Remove the target column if it exists in test data\n",
    "if target_column in test_data.columns:\n",
    "    test_data = test_data.drop(columns=[target_column])\n",
    "\n",
    "# *** Instead of dropping, keep only columns used for training ***\n",
    "# This ensures that test_data has the same columns as training_data\n",
    "test_data = test_data[training_features]\n",
    "\n",
    "# Make predictions for each row in the test data\n",
    "predictions = model.predict(test_data)\n",
    "\n",
    "# Create a DataFrame with Item_Identifier and Item_Outlet_Sales columns\n",
    "results = pd.DataFrame({\n",
    "    'Item_Identifier': index_ids,\n",
    "    'Outlet_Type': index_ids2,\n",
    "    'Item_Outlet_Sales': predictions\n",
    "})\n",
    "\n",
    "# Display the results\n",
    "print(results)\n",
    "\n",
    "# Optionally, save the results to a CSV file\n",
    "results.to_csv('predictions.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPxGzLT4f6pKMpiZupe2Txn",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
